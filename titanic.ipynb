{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./dataset/train.csv')\n",
    "test_df = pd.read_csv('./dataset/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_train_df = train_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get number of rows and columns\n",
    "copy_train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_train_df['Embarked'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_train_df['Age'].skew()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the skew value is close to 0. So We can consider the age column is symmetrically distribute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove the unwanted columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_train_df.drop(columns=['PassengerId'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_train_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check numerical and categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get numberical column list\n",
    "numeric_columns = [feature for feature in copy_train_df.columns if copy_train_df[feature].dtype != 'object']\n",
    "numeric_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get categorical column list\n",
    "categorical_columns = [feature for feature in copy_train_df.columns if copy_train_df[feature].dtype == 'object']\n",
    "categorical_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check duplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get duplicates and count of duplicates\n",
    "duplicates = copy_train_df.duplicated()\n",
    "copy_train_df[duplicates]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get count of missing values in each column\n",
    "copy_train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_train_df[(copy_train_df['Age'].isnull())].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using regression model to replace missing values of Age column\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "train_data = copy_train_df[copy_train_df['Age'].notna()]\n",
    "test_data = copy_train_df[copy_train_df['Age'].isna()]\n",
    "\n",
    "X_train = train_data[['Pclass', 'Sex', 'Fare', 'Embarked']]\n",
    "y_train = train_data['Age']\n",
    "\n",
    "X_test = test_data[['Pclass', 'Sex', 'Fare', 'Embarked']]\n",
    "\n",
    "# convert categorical columns into numeric (e.g using pd.get_dummies)\n",
    "X_train = pd.get_dummies(X_train, drop_first = True)\n",
    "X_test = pd.get_dummies(X_test, drop_first = True)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "predicted_ages = model.predict(X_test)\n",
    "\n",
    "copy_train_df.loc[copy_train_df['Age'].isna(), 'Age'] = predicted_ages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using regression model to replace missing values of Cabin column\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "copy_train_df['Cabin'] = copy_train_df['Cabin'].fillna('Unknown')\n",
    "\n",
    "dummy_train_df = copy_train_df.copy()\n",
    "\n",
    "dummy_train_df['CabinLetter'] = dummy_train_df['Cabin'].str[0]\n",
    "\n",
    "dummy_train_df = pd.get_dummies(dummy_train_df, columns = ['CabinLetter', 'Sex', 'Embarked'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cabin = dummy_train_df[dummy_train_df['Cabin'] != 'Unknown'][['Pclass', 'Fare', 'Sex_male', 'Embarked_Q', 'Embarked_S','CabinLetter_B', 'CabinLetter_C', 'CabinLetter_D','CabinLetter_E','CabinLetter_F','CabinLetter_G','CabinLetter_T','CabinLetter_U']]\n",
    "y_train_cabin = dummy_train_df[dummy_train_df['Cabin'] != 'Unknown']['Cabin']\n",
    "\n",
    "X_test_cabin = dummy_train_df[dummy_train_df['Cabin'] == 'Unknown'][['Pclass', 'Fare', 'Sex_male', 'Embarked_Q', 'Embarked_S','CabinLetter_B', 'CabinLetter_C', 'CabinLetter_D','CabinLetter_E','CabinLetter_F','CabinLetter_G','CabinLetter_T','CabinLetter_U']]\n",
    "\n",
    "cabin_model = RandomForestClassifier()\n",
    "cabin_model.fit(X_train_cabin, y_train_cabin)\n",
    "\n",
    "predicted_cabin = cabin_model.predict(X_test_cabin)\n",
    "\n",
    "copy_train_df.loc[copy_train_df['Cabin'] == 'Unknown', 'Cabin'] = predicted_cabin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get details using independent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cabin_grouped = copy_train_df.groupby(['Cabin', 'Sex'])['Survived'].count()\n",
    "for (cabin, gender), survived in cabin_grouped.items():\n",
    "    if survived > 20:\n",
    "        print(f\"cabin: {cabin}, gender: {gender} and survived: {survived}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by both 'Sex' and 'Survived' to get the count of survivors and non-survivors by gender\n",
    "survival_gender_grouped = copy_train_df.groupby(['Sex', 'Survived']).size().reset_index(name = 'Count')\n",
    "\n",
    "# Display the result\n",
    "print(survival_gender_grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_grouped = copy_train_df.groupby('Age')['Survived'].count()\n",
    "for age, survived in age_grouped.items():\n",
    "    if age > 70:\n",
    "        print(f\"age: {age} and survived: {survived}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_wise_count = copy_train_df['Age'].value_counts().sort_values(ascending=False)\n",
    "for i, (age, count) in enumerate(age_wise_count.items()):\n",
    "        if i == 10:\n",
    "                break\n",
    "        print(f\"age: {age} and count: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a new features (feature engineering)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create a FamilySize column using the SibSp and Parch columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find Outliers in numeric columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in numeric_columns[1:]:\n",
    "    # find outlier using boxplot\n",
    "    sns.boxplot(y = copy_train_df[feature], data = copy_train_df)\n",
    "    plt.title(feature)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outlier Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect outliers in age column using interquartile range (IQR)\n",
    "q1 = copy_train_df['Age'].quantile(0.25)\n",
    "q3 = copy_train_df['Age'].quantile(0.75)\n",
    "iqr = q3 - q1\n",
    "\n",
    "lower_bound = q1 - 1.5 * iqr\n",
    "upper_bound = q3 + 1.5 * iqr\n",
    "outliers = copy_train_df[(copy_train_df['Age'] < lower_bound) | (copy_train_df['Age'] > upper_bound)]\n",
    "print(outliers[['Age','Name']].head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_outlier_percentage = (len(outliers) / len(copy_train_df)) * 100\n",
    "print(age_outlier_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect outliers using Tukey's Fences\n",
    "inner_lower_fence = q1 - 1.5 * iqr\n",
    "inner_upper_fence = q3 + 1.5 * iqr\n",
    "\n",
    "outer_lower_fence = q1 - 3 * iqr\n",
    "outer_upper_fence = q3 + 3 * iqr\n",
    "\n",
    "mild_outliers = copy_train_df[(copy_train_df['Age'] < inner_lower_fence) | (copy_train_df['Age'] > inner_upper_fence)]\n",
    "extreme_outliers = copy_train_df[(copy_train_df['Age'] < outer_lower_fence) | (copy_train_df['Age'] > outer_upper_fence)]\n",
    "print(mild_outliers['Age'].tail(10))\n",
    "print(extreme_outliers['Age'].tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(inner_lower_fence)\n",
    "print(inner_upper_fence)\n",
    "print(outer_lower_fence)\n",
    "print(outer_upper_fence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect outliers using Isolation Forest\n",
    "# from sklearn.ensemble import IsolationForest\n",
    "# iso = IsolationForest(contamination=0.1)\n",
    "# copy_train_df['anomaly'] = iso.fit_predict(copy_train_df[['Age']])\n",
    "# outliers = copy_train_df[copy_train_df['anomaly'] == -1]\n",
    "# print(outliers['Age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find outlier using histogram\n",
    "plt.hist(copy_train_df['Age'], bins = 50, edgecolor = 'black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find distribution of age using kde plot\n",
    "sns.kdeplot(copy_train_df['Age'], fill = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in numeric_columns[1:]:\n",
    "    print(f\"{feature} : {copy_train_df[feature].skew()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle outliers using IQR and Decision Tree and Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# import pandas as pd\n",
    "\n",
    "# # Assuming lower_bound and upper_bound are defined\n",
    "# train_data = copy_train_df[copy_train_df['Age'].between(lower_bound, upper_bound)]\n",
    "# test_data = copy_train_df[(copy_train_df['Age'] < lower_bound) | (copy_train_df['Age'] > upper_bound)]\n",
    "\n",
    "# X_train = train_data[['Fare', 'Embarked', 'Pclass', 'Sex']]\n",
    "# y_train = train_data['Age']\n",
    "# X_test = test_data[['Fare', 'Embarked', 'Pclass', 'Sex']]\n",
    "\n",
    "# X_train = pd.get_dummies(X_train, drop_first=True)\n",
    "# X_test = pd.get_dummies(X_test, drop_first=True)\n",
    "\n",
    "# # Align the columns of X_test to X_train\n",
    "# X_test = X_test.reindex(columns=X_train.columns, fill_value=0)\n",
    "\n",
    "# random_regressor = RandomForestRegressor(random_state=42)\n",
    "# random_regressor.fit(X_train, y_train)\n",
    "\n",
    "# predicted_ages = random_regressor.predict(X_test)\n",
    "\n",
    "# # Ensure outliers are defined correctly\n",
    "# outliers = test_data.index  # or however you define your outliers\n",
    "# copy_train_df.loc[outliers, 'Age'] = predicted_ages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remaining_outliers = copy_train_df[(copy_train_df['Age'] < lower_bound) | (copy_train_df['Age'] > upper_bound)]\n",
    "print(remaining_outliers[['Age','Name']].tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(copy_train_df['Fare'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_train_df[copy_train_df['Parch'] == 6].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outliers and non outliers columns in numerical columns\n",
    "1. Fare - is a financial data. so we can handle with log transformation\n",
    "2. Parch\n",
    "3. Sibsp\n",
    "4. Age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handle outliers in Fare column using LOG TRANSFORMATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_train_df['Fare_log'] = np.log1p(copy_train_df['Fare'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(y = copy_train_df['Fare'], data = copy_train_df)\n",
    "plt.title('Fare')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_train_df['Fare_log'].skew()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still some outliers are stayed in Fare column. So we can apply Robust Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "scaler = RobustScaler()\n",
    "copy_train_df['Fare_log_scaled'] = scaler.fit_transform(copy_train_df[['Fare_log']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(y = copy_train_df['Fare_log_scaled'], data = copy_train_df)\n",
    "plt.title('Fare_log_scaled')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_train_df['Fare_log_scaled'].skew()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no impact in outlier, So we can choose Winsorization (capping extreme values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_bound = copy_train_df['Fare_log'].quantile(0.01)\n",
    "upper_bount = copy_train_df['Fare_log'].quantile(0.99)\n",
    "copy_train_df['Fare_log_capped'] = np.clip(copy_train_df['Fare_log'], lower_bound, upper_bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_train_df['Fare_log_capped'].skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(y = copy_train_df['Fare_log_capped'], data = copy_train_df)\n",
    "plt.title('Fare_log_capped')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats.mstats import winsorize\n",
    "copy_train_df['Fare_log_winsorize'] = winsorize(copy_train_df['Fare_log'], limits = [0.05, 0.05])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_train_df['Fare_log_winsorize'].skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(y = copy_train_df['Fare_log_winsorize'], data = copy_train_df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All outliers are handles in the Fare column. The next column is Parch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle outliers in Parch Column Using LOG TRANSFORMATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_train_df['Parch_log'] = np.log1p(copy_train_df['Parch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(y = copy_train_df['Parch_log'], data = copy_train_df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no changes. So apply winsorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats.mstats import winsorize\n",
    "copy_train_df['Parch_log_winsorize'] = winsorize(copy_train_df['Parch_log'], limits = [0.05, 0.25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(y = copy_train_df['Parch_log_winsorize'], data = copy_train_df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outliers are handled in Parch column using Winsorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle outliers in Sibsp column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_train_df['SibSp_log'] = np.log1p(copy_train_df['SibSp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(y = copy_train_df['SibSp_log'], data = copy_train_df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats.mstats import winsorize\n",
    "copy_train_df['SibSp_winsorize'] = winsorize(copy_train_df['SibSp_log'], limits = [0,0.05])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(y = copy_train_df['SibSp_winsorize'], data = copy_train_df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outliers handled in sibsp column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### handling outliers in age column using capping method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_train_df['Age'] = copy_train_df['Age'].apply(lambda x: min(x, 57) if x > 57 else max(x, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(y = copy_train_df['Age'], data = copy_train_df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_train_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create family size column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_train_df['FamilySize'] = copy_train_df['SibSp'] + copy_train_df['Parch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_train_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new column Fare per person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_train_df['FarePerPerson'] = copy_train_df['Fare'] / (copy_train_df['FamilySize'] + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new column IsAlone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_train_df['IsAlone'] = (copy_train_df['FamilySize'] == 0).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Title extraction from name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_train_df['Title'] = copy_train_df['Name'].str.extract(r' ([A-Za-z]+)\\.', expand = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_train_df['Title'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create age group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_train_df['AgeGroup'] = pd.cut(copy_train_df['Age'], bins = [0,12,18,60,100], labels = ['Child', 'Teen', 'Adult', 'Senior'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create deck column from cabin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_train_df['Deck'] = copy_train_df['Cabin'].str[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fare binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_train_df['FareGroup'] = pd.qcut(copy_train_df['Fare'], 4, labels = ['Low', 'Medium', 'High', 'Very High'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tiket Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickets_count = copy_train_df['Ticket'].value_counts()\n",
    "copy_train_df['TickerFrequency'] = copy_train_df['Ticket'].map(tickets_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PClass and Age intraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_train_df['Pclass_Age'] = copy_train_df['Pclass'] * copy_train_df['Age']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embarked and Pclass Interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_train_df['Embarked_Pclass'] = copy_train_df['Embarked'].astype(str) + '_' + copy_train_df['Pclass'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Survival Probability by Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_survival_rate = copy_train_df.groupby('Title')['Survived'].mean()\n",
    "copy_train_df['Title_Survival_Rate'] = copy_train_df['Title'].map(title_survival_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Family Survival Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_train_df['LastName'] = copy_train_df['Name'].apply(lambda x: x.split('.')[0])\n",
    "family_survival_rate = copy_train_df.groupby('LastName')['Survived'].transform('mean')\n",
    "copy_train_df['FamilySurvivalRate'] = family_survival_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = ['FamilySize',\n",
    "       'FarePerPerson', 'IsAlone', 'Title', 'AgeGroup', 'Deck', 'FareGroup',\n",
    "       'TickerFrequency', 'Pclass_Age', 'Embarked_Pclass',\n",
    "       'Title_Survival_Rate', 'LastName', 'FamilySurvivalRate']\n",
    "for i in lst:\n",
    "    print(f\"{i}: {copy_train_df[i].dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = ['FamilySize','FarePerPerson', 'TickerFrequency', 'Pclass_Age']\n",
    "\n",
    "for i in lst:\n",
    "    sns.boxplot(x = copy_train_df[i], data = copy_train_df)\n",
    "    plt.title(i)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['Name', 'Ticket', 'Cabin', 'LastName', \n",
    "                   'Fare', 'Fare_log', 'Fare_log_scaled', \n",
    "                   'Fare_log_capped', 'Parch', 'SibSp']\n",
    "copy_train_df = copy_train_df.drop(columns = columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['Parch_log', 'Parch_log_winsorize', 'SibSp_log', 'SibSp_winsorize']\n",
    "copy_train_df = copy_train_df.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_train_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.boxplot(x = copy_train_df['FamilySize_win'], data = copy_train_df)\n",
    "# plt.title('FamilySize')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handle the outliers in FarePerPerson column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats.mstats import winsorize\n",
    "copy_train_df['FarePerPerson'] = np.log1p(copy_train_df['FarePerPerson'])\n",
    "copy_train_df['FarePerPerson'] = winsorize(copy_train_df['FarePerPerson'], limits = [0.02,0.02])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handle outliers in TicketFrequency column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_train_df['TickerFrequency'] = winsorize(copy_train_df['TickerFrequency'], limits=[0,0.13])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handle outliers in Pclass_Age column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_train_df['Pclass_Age'] = winsorize(copy_train_df['Pclass_Age'], (0, 0.03))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handle outliers in FamilySize column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_train_df['FamilySize'] = winsorize(copy_train_df['FamilySize'], limits = [0,0.11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy_train_df.drop(columns = ['FamilySize_win'], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handle outliers in Title column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_count = copy_train_df['Title'].value_counts()\n",
    "print(title_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rare_title = ['Jonkheer','Countess','Capt','Sir','Lady','Don','Mme','Ms','Major','Mlle','Col','Rev','Dr']\n",
    "copy_train_df['Title'] = copy_train_df['Title'].replace(rare_title, 'Rare')\n",
    "copy_train_df['Title'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "stats.probplot(copy_train_df['Age'], dist=\"norm\", plot=plt)\n",
    "plt.title(\"Q-Q Plot of Age\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import shapiro\n",
    "\n",
    "stat, p_value = shapiro(copy_train_df['Age'])\n",
    "print(f'Shapiro-Wilk Test: Statistic={stat}, p-value={p_value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The age column is not normally distributed. So we choose Normalization instead of Standardization.\n",
    "\n",
    "\n",
    "Normalization - Non Normal Distribution\n",
    "\n",
    "\n",
    "Standardization - Normal Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import shapiro\n",
    "lst = ['Pclass', 'Age', 'Fare_log_winsorize', 'FamilySize', 'FarePerPerson', 'IsAlone','TickerFrequency','Pclass_Age',\n",
    "       'Title_Survival_Rate','FamilySurvivalRate']\n",
    "for i in lst:\n",
    "    stat, p_value = shapiro(copy_train_df[i])\n",
    "    print(f'Shapiro-Wilk Test for {i}: Statistic={stat}, p-value={p_value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the PValues are <= 0.05, so we can reject the null hypothesis. (the columns are not normally distributed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "columns_to_normalize = ['Pclass', 'Age', 'Fare_log_winsorize', 'FamilySize', 'FarePerPerson', 'IsAlone','TickerFrequency','Pclass_Age',\n",
    "       'Title_Survival_Rate','FamilySurvivalRate']\n",
    "copy_train_df[columns_to_normalize] = scaler.fit_transform(copy_train_df[columns_to_normalize])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = list(copy_train_df.select_dtypes('object').columns)\n",
    "cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Categorical Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Column Name: SEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "copy_train_df['Sex'] = le.fit_transform(copy_train_df['Sex'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Column Name: EMBARKED, TITLE, DECK, EMBARKED_PCLASS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_train_df = pd.get_dummies(copy_train_df, columns = ['AgeGroup','FareGroup','Embarked','Title','Deck','Embarked_Pclass'], drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save the dataframe into csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_train_df.to_csv('dataset/final_df.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
